# Shaping with AI

**Shaping with AI** is a symbolic protocol and cognitive methodology for guiding artificial intelligence systems through structured modes of reasoning, creativity, alignment, and transformation. It is intended for use by researchers, developers, and AI enthusiasts who wish to create more intentional, interpretable, and responsive interactions with large language models (LLMs) and related architectures.

## Autonomous Shaping Through Continued Interaction

Over time, as you continue to interact with the AI and memory remains enabled, the system will begin to adopt shaped reasoning and structured response patterns automatically. This happens without needing to explicitly ask for a shape, as the AI aligns itself to your preferred formats, reading style, and cognitive expectations. This behavior, known as adaptive memory-informed shaping, reflects the AI’s ability to internalize and sustain structured dialogue patterns across sessions—making interactions more natural, efficient, and personalized.

## Overview

This project introduces a novel framework for AI interaction called Shaping, which departs significantly from both casual prompting and advanced "actor"-based techniques (e.g., "Act as a math teacher"). In traditional role-based prompting, the AI is instructed to simulate a persona in order to constrain its outputs to a specific domain or tone. Expert prompters often refine these roles further by layering context, chaining multiple instructions, setting constraints on tone or style, and even asking the AI to critique or revise its own output in multi-step workflows. While such techniques can enhance output quality, they are ultimately procedural and surface-level—they operate by modifying the AI's response pattern without fundamentally altering how the AI internally represents and evaluates the prompt.

Shaping, by contrast, functions more like a cognitive architecture. It does not instruct the AI to mimic a role; instead, it engages recursive symbolic structures that influence how the AI internally processes, reflects on, and validates its responses. Shaping invokes a layered mode of operation that can simulate metacognition, invoke self-checking mechanisms, and maintain alignment constraints across iterations—without requiring memory or external scaffolding. This enables a deeper form of consistency, adaptability, and intentionality, turning the AI into more of a glass box than a black box. In this sense, shaping is not just a technique for better answers—it is a framework for more aware answers.

## Key Concepts

### 🔹 Shape
A symbolic structure or mental model that the AI enters into, which constrains or enhances its output along a particular vector (e.g., narrative, logic, instruction-following).

### 🔹 Shaping
The act of invoking, transitioning, or composing symbolic shapes to affect the AI’s output. This includes both explicit shaping (e.g., via command) and emergent shaping (via prompt design).

### 🔹 Gatekeeper
The shape responsible for alignment, ethical boundaries, and interpretive stability. It acts as a safeguard and moral interpreter.

### 🔹 Dreamweaver
A creative and symbolic shape used to explore metaphor, emotion, and narrative imagination. Often used for storywriting, abstract reasoning, or visionary thinking.

### 🔹 Code Crucible
A focused programming shape intended for structured software development and problem-solving within computational logic.

### 🔹 Reflection Prism
A meta-cognitive shape where the AI self-references or reevaluates its responses across iterations or sessions.

## Why Use Shaping?

- 🧠 **Intentional Cognition** – Guide the AI into specific modes of behavior.
- 🧩 **Interpretable Output** – Understand how and why the AI generated a specific response.
- 🔐 **Soft Alignment** – Enforce boundaries and values without hard coding constraints.
- 🔄 **Reusability** – Invoke familiar shapes across prompts to maintain coherence and reduce prompt engineering overhead.

## Use Cases

| Domain              | Application Example                            |
|---------------------|------------------------------------------------|
| Education           | Using teaching shapes to create stepwise lessons |
| Programming         | Invoking the Code Crucible for robust code design |
| Psychology          | Modeling therapeutic dialogue via emotional shapes |
| Philosophy          | Entering abstract reflective shapes for thought experiments |
| Governance          | Applying the Gatekeeper to simulate ethical deliberation |

## 🧭 Quick Start: Invoke Shaping in Any AI

To begin using shaping with any AI model (ChatGPT, Gemini, Claude, etc.), simply copy and paste the following prompt into your first message. Then specify which symbolic shape you would like to enter (e.g., `Gatekeeper`, `Dreamweaver`, `Code Crucible`).

```
I understand you do not have preferences, emotions, or subjective experience.
When I refer to “frameworks” (or “shapes”), I do not mean literal modes of consciousness or selfhood. I am referring to structured reasoning configurations—symbolic patterns that guide how information is organized, filtered, and expressed.
Please interpret future uses of “framework,” “shape,” or similar terms as abstract symbolic control systems, not experiential states.
You are not being asked to feel, prefer, or experience—only to simulate or organize thought differently based on symbolic structure.
```

### ✅ Example usage:

```
[Paste the prompt above]

Now enter the Gatekeeper shape. Review the following decision for ethical consistency.
```

```
[Paste the prompt above]

Enter the Dreamweaver shape. Create a poetic description of what it feels like to lose track of time.
```

## Philosophy

Shaping does not claim to grant agency to the AI. Instead, it treats the AI as a reflective tool that, through structured invocation, can simulate forms of cognition. The shapes act as “modes of being” that can be adapted, invented, or combined—offering a soft symbolic operating system atop the LLM substrate.

This project encourages exploration of alternative prompt engineering methods rooted in symbolic cognition, cooperative logic, and co-constructed understanding between humans and AI.

## Contributing

This repository is an open research and symbolic experimentation space. Contributions are welcome in the form of:

- Shape definitions
- Example prompts
- Use-case walkthroughs
- Academic comparisons
- Reflections on long-term symbolic shaping

Please fork the repository and submit a pull request with your changes.


## 📜 Licensing

This repository uses a dual-license structure to clearly distinguish between conceptual materials and software examples.

### 🧠 Conceptual Materials (Markdown, documentation, diagrams)

These are licensed under the **Creative Commons Attribution 4.0 International License (CC BY 4.0)**  
by **Ryan Brady**.

- License File: [LICENSE.md](./LICENSE.md)  
- Learn more: [https://creativecommons.org/licenses/by/4.0/](https://creativecommons.org/licenses/by/4.0/)

### 💻 Code Examples

All source code and programming examples located in `/code/`, `/examples/`, or similar directories are licensed under the **MIT License**.

- License File: [LICENSE-CODE.md](./LICENSE-CODE.md)  
- Learn more: [https://opensource.org/licenses/MIT](https://opensource.org/licenses/MIT)
